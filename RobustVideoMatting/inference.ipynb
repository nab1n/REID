{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model import MattingNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MattingNetwork(variant='mobilenetv3').eval().cuda()\n",
    "model.load_state_dict(torch.load('checkpoints/rvm_mobilenetv3.pth'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference on video**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from inference_utils import VideoReader, VideoWriter\n",
    "\n",
    "reader = VideoReader('videos/footage-1.mp4', transform=ToTensor())\n",
    "writer = VideoWriter('videos/output.mp4', frame_rate=30)\n",
    "\n",
    "bgr = torch.tensor([.47, 1, .6]).view(3, 1, 1).cuda()  # Green background.\n",
    "rec = [None] * 4                                       # Initial recurrent states.\n",
    "\n",
    "with torch.no_grad():\n",
    "    for src in DataLoader(reader):\n",
    "        fgr, pha, *rec = model(src.cuda(), *rec, downsample_ratio=0.25)  # Cycle the recurrent states.\n",
    "        writer.write(fgr * pha + bgr * (1 - pha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference import convert_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inference import convert_video\n",
    "\n",
    "convert_video(\n",
    "    model,                                                  # The loaded model, can be on any device (cpu or cuda).\n",
    "    input_source='videos/footage-1.mp4',                    # A video file or an image sequence directory.\n",
    "    input_resize=(1920, 1080),                              # [Optional] Resize the input (also the output).\n",
    "    downsample_ratio=0.25,                                  # [Optional] If None, make downsampled max size be 512px.\n",
    "    output_type='video',                                    # Choose \"video\" or \"png_sequence\"\n",
    "    output_composition='videos/output.mp4',                            # File path if video; directory path if png sequence.\n",
    "    output_alpha=\"pha.mp4\",                                 # [Optional] Output the raw alpha prediction.\n",
    "    output_foreground=\"fgr.mp4\",                            # [Optional] Output the raw foreground prediction.\n",
    "    output_video_mbps=4,                                    # Output video mbps. Not needed for png sequence.\n",
    "    seq_chunk=12,                                           # Process n frames at once for better parallelism.\n",
    "    num_workers=1,                                          # Only for image sequence input. Reader threads.\n",
    "    progress=True                                           # Print conversion progress.\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7bcbc1ee9b3c8125e7674f7520932b24498aac185c7ade2b6b2e968c3ccadc8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
